{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 28 # Pixel width / height\n",
    "num_labels = 10\n",
    "iterations = 2001\n",
    "\n",
    "lrate = 0.07 # Learn Rate\n",
    "layer_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder( tf.float32, shape=(None, img_size*img_size))\n",
    "y_ = tf.placeholder( tf.float32, shape=(None, num_labels))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# Weights & Biases\n",
    "W1 = tf.Variable( tf.truncated_normal([img_size*img_size, layer_size], stddev=0.1))\n",
    "b1 = tf.Variable( tf.ones([layer_size])/10)\n",
    "W2 = tf.Variable( tf.truncated_normal([layer_size, num_labels], stddev=0.1))\n",
    "b2 = tf.Variable( tf.ones([num_labels])/10)\n",
    "\n",
    "# Layers ~softmax\n",
    "y1 = tf.nn.relu( tf.matmul( x, W1) + b1)\n",
    "y = tf.matmul( y1, W2) + b2\n",
    "\n",
    "# Loss\n",
    "tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "# tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "# Training\n",
    "learn_rate = tf.train.exponential_decay(lrate,global_step,200,0.95, staircase=True)\n",
    "# tf.summary.scalar(\"learn_rate\", learn_rate)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "# Accuracy\n",
    "prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "# tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "train accuracy:\t 0.15\n",
      "cross entropy:\t 2.2662\n",
      "learn rate:\t 0.07\n",
      "step: 100\n",
      "train accuracy:\t 0.75\n",
      "cross entropy:\t 1.0095\n",
      "learn rate:\t 0.07\n",
      "step: 200\n",
      "train accuracy:\t 0.84\n",
      "cross entropy:\t 0.5510\n",
      "learn rate:\t 0.0665\n",
      "step: 300\n",
      "train accuracy:\t 0.89\n",
      "cross entropy:\t 0.4036\n",
      "learn rate:\t 0.0665\n",
      "step: 400\n",
      "train accuracy:\t 0.84\n",
      "cross entropy:\t 0.5654\n",
      "learn rate:\t 0.0631\n",
      "step: 500\n",
      "train accuracy:\t 0.91\n",
      "cross entropy:\t 0.3618\n",
      "learn rate:\t 0.0631\n",
      "step: 600\n",
      "train accuracy:\t 0.93\n",
      "cross entropy:\t 0.2947\n",
      "learn rate:\t 0.0600\n",
      "step: 700\n",
      "train accuracy:\t 0.87\n",
      "cross entropy:\t 0.4314\n",
      "learn rate:\t 0.0600\n",
      "step: 800\n",
      "train accuracy:\t 0.9\n",
      "cross entropy:\t 0.3497\n",
      "learn rate:\t 0.0570\n",
      "step: 900\n",
      "train accuracy:\t 0.91\n",
      "cross entropy:\t 0.3258\n",
      "learn rate:\t 0.0570\n",
      "step: 1000\n",
      "train accuracy:\t 0.89\n",
      "cross entropy:\t 0.3432\n",
      "learn rate:\t 0.0541\n",
      "step: 1100\n",
      "train accuracy:\t 0.9\n",
      "cross entropy:\t 0.3099\n",
      "learn rate:\t 0.0541\n",
      "step: 1200\n",
      "train accuracy:\t 0.88\n",
      "cross entropy:\t 0.3543\n",
      "learn rate:\t 0.0514\n",
      "step: 1300\n",
      "train accuracy:\t 0.98\n",
      "cross entropy:\t 0.1166\n",
      "learn rate:\t 0.0514\n",
      "step: 1400\n",
      "train accuracy:\t 0.95\n",
      "cross entropy:\t 0.2042\n",
      "learn rate:\t 0.0488\n",
      "step: 1500\n",
      "train accuracy:\t 0.92\n",
      "cross entropy:\t 0.3911\n",
      "learn rate:\t 0.0488\n",
      "step: 1600\n",
      "train accuracy:\t 0.91\n",
      "cross entropy:\t 0.2878\n",
      "learn rate:\t 0.0464\n",
      "step: 1700\n",
      "train accuracy:\t 0.88\n",
      "cross entropy:\t 0.4583\n",
      "learn rate:\t 0.0464\n",
      "step: 1800\n",
      "train accuracy:\t 0.91\n",
      "cross entropy:\t 0.3207\n",
      "learn rate:\t 0.0441\n",
      "step: 1900\n",
      "train accuracy:\t 0.94\n",
      "cross entropy:\t 0.2099\n",
      "learn rate:\t 0.0441\n",
      "step: 2000\n",
      "train accuracy:\t 0.93\n",
      "cross entropy:\t 0.2876\n",
      "learn rate:\t 0.0419\n",
      "\n",
      "TEST accuracy: 0.9126\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# writer = tf.summary.FileWriter(\"/temp/log\")\n",
    "# writer.add_graph(sess.graph)\n",
    "\n",
    "# Session\n",
    "for step in range(0,iterations):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(optimizer, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if(step % 100 == 0):\n",
    "        a, c, l = sess.run([accuracy, cross_entropy, learn_rate], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "#         s = sess.run(summ, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "#         writer.add_summary(s,step)\n",
    "        print('step:',step)\n",
    "        print('train accuracy:\\t', a)\n",
    "        print('cross entropy:\\t', str(c)[:6])\n",
    "        print('learn rate:\\t', str(l)[:6])\n",
    "\n",
    "# Test Data Accuracy\n",
    "print('\\nTEST accuracy:', sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
